{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ======================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_getting-started-session-based-01-etl-with-nvtabular/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# FSI Benchmark Models for Financial Product Recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "This notebook creates a simple benchmark model for financial product recommendation using the FSI synthetic demo dataset. We implement a rule-based baseline model to compare against the transformer-based models in subsequent notebooks:\n",
    "\n",
    "1. **Rule-based Model**: Simple heuristic model using business rules and domain knowledge\n",
    "\n",
    "The model predicts `converts_for_a_topup` (binary classification) and is evaluated using **log-loss** and **AUROC** metrics.\n",
    "\n",
    "## Goal\n",
    "Create baseline performance benchmarks to compare against the transformer-based recommendation models implemented in notebooks 01 and 02.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Import Required Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, roc_auc_score, classification_report\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Define Input/Output Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data directory: ./data/\n",
      "Output directory: ./benchmark_results/\n"
     ]
    }
   ],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"./data/\")\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", \"./benchmark_results/\")\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Input data directory: {INPUT_DATA_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Load and Explore FSI Synthetic Demo Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: ./data/synthetic_fsi/synthetic_demo_data.parquet\n",
      "✅ Loaded 440,787 rows and 18 columns\n",
      "📊 Data shape: (440787, 18)\n",
      "📋 Columns: ['session_date', 'loan_id', 'has_mobile_app', 'debtiq_enrolled', 'pa_eligible', 'topup_eligible', 'ita_eligible', 'email_sent_in_last_90_days', 'dm_sent_in_last_90_days', 'fico', 'income_', 'existing_loan_size_', 'current_loan_mob', 'offer___carousel', 'servicing___carousel', 'feature_sheet', 'bottom_sheet', 'converts_for_a_topup']\n",
      "\n",
      "==================================================\n",
      "DATASET OVERVIEW\n",
      "==================================================\n",
      "Dataset shape: (440787, 18)\n",
      "Memory usage: 148.76 MB\n",
      "Date range: 2025-05-01 00:00:00 to 2025-05-30 00:00:00\n",
      "Unique loans: 148,570\n",
      "\n",
      "==================================================\n",
      "TARGET VARIABLE DISTRIBUTION\n",
      "==================================================\n",
      "Target variable: converts_for_a_topup\n",
      "  - No conversion (0): 437,366 (99.22%)\n",
      "  - Conversion (1): 3,421 (0.78%)\n",
      "  - Conversion rate: 0.78%\n",
      "\n",
      "==================================================\n",
      "MISSING VALUES\n",
      "==================================================\n",
      "✅ No missing values found\n",
      "\n",
      "==================================================\n",
      "SAMPLE DATA (First 5 rows)\n",
      "==================================================\n",
      "  session_date  loan_id  has_mobile_app  debtiq_enrolled  pa_eligible  \\\n",
      "0   2025-05-22  4954838               1                1            1   \n",
      "1   2025-05-21  4765835               1                1            1   \n",
      "2   2025-05-21  4185554               0                0            1   \n",
      "3   2025-05-21  7019817               0                0            1   \n",
      "4   2025-05-24  8168610               0                0            1   \n",
      "\n",
      "   topup_eligible  ita_eligible  email_sent_in_last_90_days  \\\n",
      "0               1             1                          17   \n",
      "1               1             1                          24   \n",
      "2               1             1                          20   \n",
      "3               1             1                          17   \n",
      "4               1             1                          19   \n",
      "\n",
      "   dm_sent_in_last_90_days  fico  income_  existing_loan_size_  \\\n",
      "0                        2   807    57422                10857   \n",
      "1                        1   741    63181                 9287   \n",
      "2                        2   745    50730                 9720   \n",
      "3                        1   741   148623                10786   \n",
      "4                        1   752   110899                11537   \n",
      "\n",
      "   current_loan_mob offer___carousel servicing___carousel feature_sheet  \\\n",
      "0                 9            Topup                  ITA           ITA   \n",
      "1                28            Topup                Topup         blank   \n",
      "2                28            Topup                Topup           ITA   \n",
      "3                12            Topup                  ITA         blank   \n",
      "4                27            Topup                  ITA           ITA   \n",
      "\n",
      "  bottom_sheet  converts_for_a_topup  \n",
      "0          ITA                     0  \n",
      "1          ITA                     0  \n",
      "2          ITA                     0  \n",
      "3          ITA                     0  \n",
      "4          ITA                     0  \n"
     ]
    }
   ],
   "source": [
    "# Load the synthetic FSI demo data\n",
    "data_path = os.path.join(INPUT_DATA_DIR, \"synthetic_fsi\", \"synthetic_demo_data.parquet\")\n",
    "print(f\"Loading data from: {data_path}\")\n",
    "\n",
    "df = pd.read_parquet(data_path)\n",
    "print(f\"✅ Loaded {len(df):,} rows and {len(df.columns)} columns\")\n",
    "print(f\"📊 Data shape: {df.shape}\")\n",
    "print(f\"📋 Columns: {list(df.columns)}\")\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"Date range: {df['session_date'].min()} to {df['session_date'].max()}\")\n",
    "print(f\"Unique loans: {df['loan_id'].nunique():,}\")\n",
    "\n",
    "# Target distribution\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"TARGET VARIABLE DISTRIBUTION\")\n",
    "print(\"=\" * 50)\n",
    "target_counts = df['converts_for_a_topup'].value_counts()\n",
    "target_pct = df['converts_for_a_topup'].value_counts(normalize=True) * 100\n",
    "print(f\"Target variable: converts_for_a_topup\")\n",
    "print(f\"  - No conversion (0): {target_counts[0]:,} ({target_pct[0]:.2f}%)\")\n",
    "print(f\"  - Conversion (1): {target_counts[1]:,} ({target_pct[1]:.2f}%)\")\n",
    "print(f\"  - Conversion rate: {target_pct[1]:.2f}%\")\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"MISSING VALUES\")\n",
    "print(\"=\" * 50)\n",
    "missing_values = df.isnull().sum()\n",
    "if missing_values.sum() > 0:\n",
    "    print(missing_values[missing_values > 0])\n",
    "else:\n",
    "    print(\"✅ No missing values found\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"SAMPLE DATA (First 5 rows)\")\n",
    "print(\"=\" * 50)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Feature Engineering and Data Preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Creating engineered features...\n",
      "✅ Feature engineering completed. New shape: (440787, 26)\n",
      "📋 Feature sets defined:\n",
      "  - Categorical features: 6\n",
      "  - Binary features: 5\n",
      "  - Numerical features: 12\n",
      "  - Total features: 23\n",
      "  - Target: converts_for_a_topup\n"
     ]
    }
   ],
   "source": [
    "# Create additional features for modeling\n",
    "print(\"🔧 Creating engineered features...\")\n",
    "\n",
    "# Convert session_date to datetime\n",
    "df['session_date'] = pd.to_datetime(df['session_date'])\n",
    "\n",
    "# Extract temporal features\n",
    "df['day_of_week'] = df['session_date'].dt.dayofweek\n",
    "df['month'] = df['session_date'].dt.month\n",
    "df['day_of_month'] = df['session_date'].dt.day\n",
    "\n",
    "# Create loan-to-income ratio\n",
    "df['loan_to_income_ratio'] = df['existing_loan_size_'] / df['income_']\n",
    "\n",
    "# Create marketing engagement score\n",
    "df['marketing_engagement'] = df['email_sent_in_last_90_days'] + df['dm_sent_in_last_90_days']\n",
    "\n",
    "# Create eligibility score (sum of all eligibility flags)\n",
    "eligibility_cols = ['pa_eligible', 'topup_eligible', 'ita_eligible']\n",
    "df['eligibility_score'] = df[eligibility_cols].sum(axis=1)\n",
    "\n",
    "# Create FICO score categories\n",
    "df['fico_category'] = pd.cut(df['fico'], \n",
    "                            bins=[0, 580, 669, 739, 799, 850], \n",
    "                            labels=['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'])\n",
    "\n",
    "# Create income categories\n",
    "df['income_category'] = pd.cut(df['income_'], \n",
    "                              bins=[0, 30000, 50000, 75000, 100000, np.inf], \n",
    "                              labels=['Low', 'Lower-Mid', 'Mid', 'Upper-Mid', 'High'])\n",
    "\n",
    "print(f\"✅ Feature engineering completed. New shape: {df.shape}\")\n",
    "\n",
    "# Define feature sets for modeling\n",
    "# Categorical features\n",
    "categorical_features = [\n",
    "    'offer___carousel', 'servicing___carousel', 'feature_sheet', 'bottom_sheet',\n",
    "    'fico_category', 'income_category'\n",
    "]\n",
    "\n",
    "# Binary features\n",
    "binary_features = [\n",
    "    'has_mobile_app', 'debtiq_enrolled', 'pa_eligible', 'topup_eligible', 'ita_eligible'\n",
    "]\n",
    "\n",
    "# Numerical features\n",
    "numerical_features = [\n",
    "    'fico', 'income_', 'existing_loan_size_', 'current_loan_mob',\n",
    "    'email_sent_in_last_90_days', 'dm_sent_in_last_90_days',\n",
    "    'loan_to_income_ratio', 'marketing_engagement', 'eligibility_score',\n",
    "    'day_of_week', 'month', 'day_of_month'\n",
    "]\n",
    "\n",
    "# All features for modeling\n",
    "all_features = categorical_features + binary_features + numerical_features\n",
    "target = 'converts_for_a_topup'\n",
    "\n",
    "print(f\"📋 Feature sets defined:\")\n",
    "print(f\"  - Categorical features: {len(categorical_features)}\")\n",
    "print(f\"  - Binary features: {len(binary_features)}\")\n",
    "print(f\"  - Numerical features: {len(numerical_features)}\")\n",
    "print(f\"  - Total features: {len(all_features)}\")\n",
    "print(f\"  - Target: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Split Data into Train/Test Sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Data split completed:\n",
      "  - Training set: 352,629 samples\n",
      "  - Test set: 88,158 samples\n",
      "  - Features: 23\n",
      "  - Train conversion rate: 0.0078\n",
      "  - Test conversion rate: 0.0078\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = df[all_features].copy()\n",
    "y = df[target].copy()\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"📊 Data split completed:\")\n",
    "print(f\"  - Training set: {X_train.shape[0]:,} samples\")\n",
    "print(f\"  - Test set: {X_test.shape[0]:,} samples\")\n",
    "print(f\"  - Features: {X_train.shape[1]}\")\n",
    "print(f\"  - Train conversion rate: {y_train.mean():.4f}\")\n",
    "print(f\"  - Test conversion rate: {y_test.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Rule-Based Model\n",
    "\n",
    "### Model Implementation\n",
    "\n",
    "This model uses business logic and domain knowledge to make predictions. The rules are based on:\n",
    "- Customer financial profile (FICO, income, loan-to-income ratio)\n",
    "- Eligibility flags\n",
    "- Marketing engagement\n",
    "- Historical interaction patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Initializing Rule-Based Model...\n",
      "📊 Making predictions with Rule-Based Model...\n",
      "✅ Rule-Based Model predictions completed\n"
     ]
    }
   ],
   "source": [
    "class RuleBasedModel:\n",
    "    \"\"\"Rule-based model for financial product recommendation\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Rule-Based Model\"\n",
    "        self.rules = {\n",
    "            'high_fico_high_income': {'weight': 0.3, 'threshold': {'fico': 740, 'income_': 75000}},\n",
    "            'high_eligibility': {'weight': 0.25, 'threshold': {'eligibility_score': 2}},\n",
    "            'high_engagement': {'weight': 0.2, 'threshold': {'marketing_engagement': 15}},\n",
    "            'low_loan_to_income': {'weight': 0.15, 'threshold': {'loan_to_income_ratio': 0.3}},\n",
    "            'mobile_app_user': {'weight': 0.1, 'threshold': {'has_mobile_app': 1}}\n",
    "        }\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Predict probabilities based on business rules\"\"\"\n",
    "        probabilities = np.zeros(len(X))\n",
    "        \n",
    "        for rule_name, rule_config in self.rules.items():\n",
    "            weight = rule_config['weight']\n",
    "            \n",
    "            if rule_name == 'high_fico_high_income':\n",
    "                condition = ((X['fico'] >= rule_config['threshold']['fico']) & \n",
    "                           (X['income_'] >= rule_config['threshold']['income_']))\n",
    "            elif rule_name == 'high_eligibility':\n",
    "                condition = X['eligibility_score'] >= rule_config['threshold']['eligibility_score']\n",
    "            elif rule_name == 'high_engagement':\n",
    "                condition = X['marketing_engagement'] >= rule_config['threshold']['marketing_engagement']\n",
    "            elif rule_name == 'low_loan_to_income':\n",
    "                condition = X['loan_to_income_ratio'] <= rule_config['threshold']['loan_to_income_ratio']\n",
    "            elif rule_name == 'mobile_app_user':\n",
    "                condition = X['has_mobile_app'] == rule_config['threshold']['has_mobile_app']\n",
    "            \n",
    "            probabilities += condition.astype(float) * weight\n",
    "        \n",
    "        # Apply sigmoid to normalize probabilities\n",
    "        probabilities = 1 / (1 + np.exp(-probabilities))\n",
    "        \n",
    "        # Return probabilities for both classes\n",
    "        return np.column_stack([1 - probabilities, probabilities])\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"Make binary predictions\"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas[:, 1] >= threshold).astype(int)\n",
    "\n",
    "# Initialize and train rule-based model\n",
    "print(\"🔧 Initializing Rule-Based Model...\")\n",
    "rule_model = RuleBasedModel()\n",
    "\n",
    "# Make predictions\n",
    "print(\"📊 Making predictions with Rule-Based Model...\")\n",
    "rule_train_probas = rule_model.predict_proba(X_train)\n",
    "rule_test_probas = rule_model.predict_proba(X_test)\n",
    "\n",
    "rule_train_preds = rule_model.predict(X_train)\n",
    "rule_test_preds = rule_model.predict(X_test)\n",
    "\n",
    "print(\"✅ Rule-Based Model predictions completed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RULE-BASED MODEL EVALUATION\n",
      "============================================================\n",
      "Training Metrics:\n",
      "  - Log-Loss: 1.0202\n",
      "  - AUROC: 0.7480\n",
      "\n",
      "Test Metrics:\n",
      "  - Log-Loss: 1.0195\n",
      "  - AUROC: 0.7520\n",
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     87474\n",
      "           1       0.01      1.00      0.02       684\n",
      "\n",
      "    accuracy                           0.01     88158\n",
      "   macro avg       0.00      0.50      0.01     88158\n",
      "weighted avg       0.00      0.01      0.00     88158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Rule-Based Model\n",
    "print(\"=\" * 60)\n",
    "print(\"RULE-BASED MODEL EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate metrics\n",
    "train_logloss = log_loss(y_train, rule_train_probas)\n",
    "test_logloss = log_loss(y_test, rule_test_probas)\n",
    "\n",
    "train_auc = roc_auc_score(y_train, rule_train_probas[:, 1])\n",
    "test_auc = roc_auc_score(y_test, rule_test_probas[:, 1])\n",
    "\n",
    "print(f\"Training Metrics:\")\n",
    "print(f\"  - Log-Loss: {train_logloss:.4f}\")\n",
    "print(f\"  - AUROC: {train_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nTest Metrics:\")\n",
    "print(f\"  - Log-Loss: {test_logloss:.4f}\")\n",
    "print(f\"  - AUROC: {test_auc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, rule_test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Results Summary and Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK SUMMARY\n",
      "================================================================================\n",
      "📊 Dataset: FSI Synthetic Demo Data\n",
      "   - Total samples: 440,787\n",
      "   - Features: 23\n",
      "   - Target: converts_for_a_topup\n",
      "   - Conversion rate: 0.78%\n",
      "\n",
      "🎯 Rule-Based Model Performance:\n",
      "   - Training AUROC: 0.7480\n",
      "   - Test AUROC: 0.7520\n",
      "   - Training Log-Loss: 1.0202\n",
      "   - Test Log-Loss: 1.0195\n",
      "\n",
      "📋 Rule-Based Model Logic:\n",
      "   - High FICO + High Income (weight: 0.3)\n",
      "   - High Eligibility Score (weight: 0.25)\n",
      "   - High Marketing Engagement (weight: 0.2)\n",
      "   - Low Loan-to-Income Ratio (weight: 0.15)\n",
      "   - Mobile App Usage (weight: 0.1)\n",
      "\n",
      "🔮 Next Steps:\n",
      "   1. Compare this baseline with transformer models in notebooks 01-02\n",
      "   2. Analyze which business rules are most effective\n",
      "   3. Consider additional rule refinements based on domain expertise\n",
      "   4. Evaluate business impact and deployment considerations\n"
     ]
    }
   ],
   "source": [
    "# Create summary of results\n",
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"📊 Dataset: FSI Synthetic Demo Data\")\n",
    "print(f\"   - Total samples: {len(df):,}\")\n",
    "print(f\"   - Features: {len(all_features)}\")\n",
    "print(f\"   - Target: {target}\")\n",
    "print(f\"   - Conversion rate: {df[target].mean():.2%}\")\n",
    "\n",
    "print(f\"\\n🎯 Rule-Based Model Performance:\")\n",
    "print(f\"   - Training AUROC: {train_auc:.4f}\")\n",
    "print(f\"   - Test AUROC: {test_auc:.4f}\")\n",
    "print(f\"   - Training Log-Loss: {train_logloss:.4f}\")\n",
    "print(f\"   - Test Log-Loss: {test_logloss:.4f}\")\n",
    "\n",
    "print(f\"\\n📋 Rule-Based Model Logic:\")\n",
    "print(f\"   - High FICO + High Income (weight: 0.3)\")\n",
    "print(f\"   - High Eligibility Score (weight: 0.25)\")\n",
    "print(f\"   - High Marketing Engagement (weight: 0.2)\")\n",
    "print(f\"   - Low Loan-to-Income Ratio (weight: 0.15)\")\n",
    "print(f\"   - Mobile App Usage (weight: 0.1)\")\n",
    "\n",
    "print(f\"\\n🔮 Next Steps:\")\n",
    "print(f\"   1. Compare this baseline with transformer models in notebooks 01-02\")\n",
    "print(f\"   2. Analyze which business rules are most effective\")\n",
    "print(f\"   3. Consider additional rule refinements based on domain expertise\")\n",
    "print(f\"   4. Evaluate business impact and deployment considerations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 Saving benchmark results...\n",
      "✅ Benchmark results saved to: ./benchmark_results/benchmark_results.json\n",
      "\n",
      "============================================================\n",
      "FINAL BENCHMARK METRICS\n",
      "============================================================\n",
      "Rule-Based Model Performance:\n",
      "  - Test AUROC: 0.7520\n",
      "  - Test Log-Loss: 1.0195\n",
      "  - Training AUROC: 0.7480\n",
      "  - Training Log-Loss: 1.0202\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save benchmark results\n",
    "print(\"\\n💾 Saving benchmark results...\")\n",
    "\n",
    "# Create benchmark results structure\n",
    "benchmark_results = {\n",
    "    'dataset_info': {\n",
    "        'total_samples': len(df),\n",
    "        'features': len(all_features),\n",
    "        'conversion_rate': float(df[target].mean()),\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test)\n",
    "    },\n",
    "    'rule_based_model': {\n",
    "        'train_log_loss': float(train_logloss),\n",
    "        'test_log_loss': float(test_logloss),\n",
    "        'train_auroc': float(train_auc),\n",
    "        'test_auroc': float(test_auc),\n",
    "        'model_type': 'Rule-Based',\n",
    "        'rules': {\n",
    "            'high_fico_high_income': 0.3,\n",
    "            'high_eligibility': 0.25,\n",
    "            'high_engagement': 0.2,\n",
    "            'low_loan_to_income': 0.15,\n",
    "            'mobile_app_user': 0.1\n",
    "        }\n",
    "    },\n",
    "    'timestamp': datetime.now().isoformat()\n",
    "}\n",
    "\n",
    "# Save to JSON file\n",
    "import json\n",
    "results_file = os.path.join(OUTPUT_DIR, 'benchmark_results.json')\n",
    "with open(results_file, 'w') as f:\n",
    "    json.dump(benchmark_results, f, indent=2)\n",
    "\n",
    "print(f\"✅ Benchmark results saved to: {results_file}\")\n",
    "\n",
    "# Display final metrics summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FINAL BENCHMARK METRICS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Rule-Based Model Performance:\")\n",
    "print(f\"  - Test AUROC: {test_auc:.4f}\")\n",
    "print(f\"  - Test Log-Loss: {test_logloss:.4f}\")\n",
    "print(f\"  - Training AUROC: {train_auc:.4f}\")\n",
    "print(f\"  - Training Log-Loss: {train_logloss:.4f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "BENCHMARK NOTEBOOK COMPLETED SUCCESSFULLY! 🎉\n",
      "================================================================================\n",
      "\n",
      "📊 This rule-based baseline model provides a simple, interpretable benchmark\n",
      "for comparing against more complex transformer-based models.\n",
      "\n",
      "🔍 Key advantages of the rule-based approach:\n",
      "  - Highly interpretable business logic\n",
      "  - Fast training and inference\n",
      "  - Easy to modify and tune rules\n",
      "  - No complex feature preprocessing required\n",
      "  - Transparent decision-making process\n",
      "\n",
      "📈 Use these baseline metrics to evaluate whether more complex models\n",
      "provide sufficient performance improvements to justify their complexity.\n",
      "\n",
      "🎯 Baseline Performance to Beat:\n",
      "  - Test AUROC: 0.7520\n",
      "  - Test Log-Loss: 1.0195\n",
      "\n",
      "📂 Results have been saved to: ./benchmark_results/\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"BENCHMARK NOTEBOOK COMPLETED SUCCESSFULLY! 🎉\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n📊 This rule-based baseline model provides a simple, interpretable benchmark\")\n",
    "print(\"for comparing against more complex transformer-based models.\")\n",
    "print(\"\\n🔍 Key advantages of the rule-based approach:\")\n",
    "print(\"  - Highly interpretable business logic\")\n",
    "print(\"  - Fast training and inference\")\n",
    "print(\"  - Easy to modify and tune rules\")\n",
    "print(\"  - No complex feature preprocessing required\")\n",
    "print(\"  - Transparent decision-making process\")\n",
    "\n",
    "print(\"\\n📈 Use these baseline metrics to evaluate whether more complex models\")\n",
    "print(\"provide sufficient performance improvements to justify their complexity.\")\n",
    "\n",
    "print(f\"\\n🎯 Baseline Performance to Beat:\")\n",
    "print(f\"  - Test AUROC: {test_auc:.4f}\")\n",
    "print(f\"  - Test Log-Loss: {test_logloss:.4f}\")\n",
    "\n",
    "print(f\"\\n📂 Results have been saved to: {OUTPUT_DIR}\")\n",
    "print(\"=\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
