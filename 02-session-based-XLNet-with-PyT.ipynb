{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97250792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "# Each user is responsible for checking the content of datasets and the\n",
    "# applicable licenses and determining if suitable for the intended use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2228da",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_transformers4rec_getting-started-session-based-02-session-based-xlnet-with-pyt/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Session-based Recommendation with XLNET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8aa005",
   "metadata": {},
   "source": [
    "This notebook is created using the latest stable [merlin-pytorch](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-pytorch/tags) container.\n",
    "\n",
    "In this notebook we introduce the [Transformers4Rec](https://github.com/NVIDIA-Merlin/Transformers4Rec) library for sequential and session-based recommendation. This notebook uses the PyTorch API. Transformers4Rec integrates with the popular [HuggingFace’s Transformers](https://github.com/huggingface/transformers) and makes it possible to experiment with a cutting-edge implementation of the latest NLP Transformer architectures.  \n",
    "\n",
    "We demonstrate how to build a session-based recommendation model with the [XLNET](https://arxiv.org/abs/1906.08237) Transformer architecture. The XLNet architecture was designed to leverage the best of both auto-regressive language modeling and auto-encoding with its Permutation Language Modeling training method. In this example we will use XLNET with masked language modeling (MLM) training method, which showed very promising results in the experiments conducted in our [ACM RecSys'21 paper](https://github.com/NVIDIA-Merlin/publications/blob/main/2021_acm_recsys_transformers4rec/recsys21_transformers4rec_paper.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3e715",
   "metadata": {},
   "source": [
    "In the previous notebook we went through our ETL pipeline with the NVTabular library, and created sequential features to be used in training a session-based recommendation model. In this notebook we will learn:\n",
    "\n",
    "- Accelerating data loading of parquet files with multiple features on PyTorch using NVTabular library\n",
    "- Training and evaluating a Transformer-based (XLNET-MLM) session-based recommendation model with multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b68414-487c-4090-88f2-2cd851df11b1",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Adaptation for FSI Demo Dataset\n",
    "\n",
    "This notebook has been adapted to work with the **Financial Services Industry (FSI) synthetic demo dataset** from the first notebook. Key changes include:\n",
    "\n",
    "- **Main Item Feature**: Using `product_interaction-list` (combinations of financial offers and services) instead of `item_id-list`\n",
    "- **Feature Set**: Includes FSI-specific features like FICO scores, income, loan details, eligibility flags, and marketing touchpoints\n",
    "- **Sequence Length**: Reduced `max_sequence_length` to 10 for financial interaction sequences (typically shorter than e-commerce sessions)\n",
    "- **Temporal Range**: Training on days 21-28 instead of 1-7 (based on the FSI data's temporal structure)\n",
    "- **Business Context**: Modeling loan customer journeys through financial product recommendations and services\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359e04dc",
   "metadata": {},
   "source": [
    "## Build a DL model with Transformers4Rec library  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da66684",
   "metadata": {},
   "source": [
    "Transformers4Rec supports multiple input features and provides configurable building blocks that can be easily combined for custom architectures:\n",
    "\n",
    "- [TabularSequenceFeatures](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.TabularSequenceFeatures) class that reads from schema and creates an input block. This input module combines different types of features (continuous, categorical & text) to a sequence.\n",
    "-  [MaskSequence](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/torch/masking.py) to define masking schema and prepare the masked inputs and labels for the selected LM task.\n",
    "-  [TransformerBlock](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.TransformerBlock) class that supports HuggingFace Transformers for session-based and sequential-based recommendation models.\n",
    "-  [SequentialBlock](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.SequentialBlock) creates the body by mimicking [torch.nn.sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html) class. It is designed to define our model as a sequence of layers.\n",
    "-  [Head](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.Head) where we define the prediction task of the model.\n",
    "-  [NextItemPredictionTask](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.NextItemPredictionTask) is the class to support next item prediction task.\n",
    "- [Trainer](https://nvidia-merlin.github.io/Transformers4Rec/stable/api/transformers4rec.torch.html#transformers4rec.torch.Trainer) extends the `Trainer` class from HF transformers and manages the model training and evaluation.\n",
    "\n",
    "You can check the [full documentation](https://nvidia-merlin.github.io/Transformers4Rec/) of Transformers4Rec if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d5b3e",
   "metadata": {},
   "source": [
    "Figure 1 illustrates Transformers4Rec meta-architecture and how each module/block interacts with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17f66e",
   "metadata": {},
   "source": [
    "![tf4rec_meta](images/tf4rec_meta2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599efc90",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ba89970",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/usr/local/lib/python3.8/dist-packages/merlin/dtypes/mappings/tf.py:52: UserWarning: Tensorflow dtype mappings did not load successfully due to an error: No module named 'tensorflow'\n",
      "  warn(f\"Tensorflow dtype mappings did not load successfully due to an error: {exc.msg}\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import glob\n",
    "import torch \n",
    "\n",
    "from transformers4rec import torch as tr\n",
    "from transformers4rec.torch.ranking_metric import NDCGAt, AvgPrecisionAt, RecallAt\n",
    "from transformers4rec.torch.utils.examples_utils import wipe_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2a0c5",
   "metadata": {},
   "source": [
    "Transformers4Rec library relies on a schema object to automatically build all necessary layers to represent, normalize and aggregate input features. As you can see below, `schema.pb` is a protobuf file that contains metadata including statistics about features such as cardinality, min and max values and also tags features based on their characteristics and dtypes (e.g., categorical, continuous, list, integer)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510b6ef",
   "metadata": {},
   "source": [
    "### Set the schema object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a0518a-eb01-4ac4-9c6d-36b328985765",
   "metadata": {},
   "source": [
    "We create the schema object by reading the processed train parquet file generated by NVTabular pipeline in the previous, `01-ETL-with-NVTabular`, notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fcfcaa-f228-4ee6-808c-1ec03f481b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_DATA_DIR = os.environ.get(\"INPUT_DATA_DIR\", \"/workspace/data\")\n",
    "OUTPUT_DIR = os.environ.get(\"OUTPUT_DIR\", f\"{INPUT_DATA_DIR}/sessions_by_day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1299fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/merlin/schema/tags.py:149: UserWarning: Compound tags like Tags.ITEM_ID have been deprecated and will be removed in a future version. Please use the atomic versions of these tags, like [<Tags.ITEM: 'item'>, <Tags.ID: 'id'>].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from merlin.schema import Schema\n",
    "from merlin.io import Dataset\n",
    "\n",
    "train = Dataset(os.path.join(INPUT_DATA_DIR, \"processed_nvt/part_0.parquet\"))\n",
    "schema = train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f426f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select FSI features for training - using product_interaction as main item sequence\n",
    "# and including both categorical and continuous features from the FSI dataset\n",
    "schema = schema.select_by_name([\n",
    "    'product_interaction-list',      # Main item sequence (offers + services combinations)\n",
    "    'offer___carousel-list',         # Individual offer types\n",
    "    'servicing___carousel-list',     # Individual service types  \n",
    "    'feature_sheet-list',            # Feature sheet types\n",
    "    'bottom_sheet-list',             # Bottom sheet types\n",
    "    'has_mobile_app-list',           # Binary features\n",
    "    'debtiq_enrolled-list',\n",
    "    'pa_eligible-list',\n",
    "    'topup_eligible-list',\n",
    "    'ita_eligible-list',\n",
    "    'fico-list',                     # Continuous features\n",
    "    'income_-list',\n",
    "    'existing_loan_size_-list',\n",
    "    'current_loan_mob-list',\n",
    "    'email_sent_in_last_90_days-list',\n",
    "    'dm_sent_in_last_90_days-list'\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ba2ad-784b-433a-976e-6c5ba26d8b18",
   "metadata": {},
   "source": [
    "Let's print out the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5034fad-bda3-48dc-91c6-a3c8076595e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tags</th>\n",
       "      <th>dtype</th>\n",
       "      <th>is_list</th>\n",
       "      <th>is_ragged</th>\n",
       "      <th>properties.num_buckets</th>\n",
       "      <th>properties.freq_threshold</th>\n",
       "      <th>properties.max_size</th>\n",
       "      <th>properties.start_index</th>\n",
       "      <th>properties.cat_path</th>\n",
       "      <th>properties.embedding_sizes.cardinality</th>\n",
       "      <th>properties.embedding_sizes.dimension</th>\n",
       "      <th>properties.domain.min</th>\n",
       "      <th>properties.domain.max</th>\n",
       "      <th>properties.domain.name</th>\n",
       "      <th>properties.value_count.min</th>\n",
       "      <th>properties.value_count.max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>product_interaction-list</td>\n",
       "      <td>(Tags.ID, Tags.CATEGORICAL, Tags.ITEM_ID, Tags...</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.product_interaction.parquet</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>product_interaction</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>offer___carousel-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.offer___carousel.parquet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>offer___carousel</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>servicing___carousel-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.servicing___carousel.parquet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>servicing___carousel</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feature_sheet-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.feature_sheet.parquet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>feature_sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bottom_sheet-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.bottom_sheet.parquet</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>bottom_sheet</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>has_mobile_app-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.has_mobile_app.parquet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>has_mobile_app</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>debtiq_enrolled-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.debtiq_enrolled.parquet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>debtiq_enrolled</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>pa_eligible-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.pa_eligible.parquet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pa_eligible</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>topup_eligible-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.topup_eligible.parquet</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>topup_eligible</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ita_eligible-list</td>\n",
       "      <td>(Tags.CATEGORICAL, Tags.LIST)</td>\n",
       "      <td>DType(name='int64', element_type=&lt;ElementType....</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>.//categories/unique.ita_eligible.parquet</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ita_eligible</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fico-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>income_-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>existing_loan_size_-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>current_loan_mob-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>email_sent_in_last_90_days-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dm_sent_in_last_90_days-list</td>\n",
       "      <td>(Tags.CONTINUOUS, Tags.LIST)</td>\n",
       "      <td>DType(name='float64', element_type=&lt;ElementTyp...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "[{'name': 'product_interaction-list', 'tags': {<Tags.ID: 'id'>, <Tags.CATEGORICAL: 'categorical'>, <Tags.ITEM_ID: 'item_id'>, <Tags.ITEM: 'item'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.product_interaction.parquet', 'embedding_sizes': {'cardinality': 8.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 7, 'name': 'product_interaction'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'offer___carousel-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.offer___carousel.parquet', 'embedding_sizes': {'cardinality': 5.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 4, 'name': 'offer___carousel'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'servicing___carousel-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.servicing___carousel.parquet', 'embedding_sizes': {'cardinality': 5.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 4, 'name': 'servicing___carousel'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'feature_sheet-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.feature_sheet.parquet', 'embedding_sizes': {'cardinality': 5.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 4, 'name': 'feature_sheet'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'bottom_sheet-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.bottom_sheet.parquet', 'embedding_sizes': {'cardinality': 5.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 4, 'name': 'bottom_sheet'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'has_mobile_app-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.has_mobile_app.parquet', 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 2, 'name': 'has_mobile_app'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'debtiq_enrolled-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.debtiq_enrolled.parquet', 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 2, 'name': 'debtiq_enrolled'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'pa_eligible-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.pa_eligible.parquet', 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 2, 'name': 'pa_eligible'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'topup_eligible-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.topup_eligible.parquet', 'embedding_sizes': {'cardinality': 3.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 2, 'name': 'topup_eligible'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'ita_eligible-list', 'tags': {<Tags.CATEGORICAL: 'categorical'>, <Tags.LIST: 'list'>}, 'properties': {'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'start_index': 0.0, 'cat_path': './/categories/unique.ita_eligible.parquet', 'embedding_sizes': {'cardinality': 2.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 1, 'name': 'ita_eligible'}, 'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'fico-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'income_-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'existing_loan_size_-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'current_loan_mob-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'email_sent_in_last_90_days-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}, {'name': 'dm_sent_in_last_90_days-list', 'tags': {<Tags.CONTINUOUS: 'continuous'>, <Tags.LIST: 'list'>}, 'properties': {'value_count': {'min': 1, 'max': 9}}, 'dtype': DType(name='float64', element_type=<ElementType.Float: 'float'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None), Dimension(min=1, max=9)))), 'is_list': True, 'is_ragged': True}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cacefa",
   "metadata": {},
   "source": [
    "### Define the sequential input module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203795d",
   "metadata": {},
   "source": [
    "Below we define our `input` block using the `TabularSequenceFeatures` [class](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/torch/features/sequence.py#L97). The `from_schema()` method processes the schema and creates the necessary layers to represent features and aggregate them. It keeps only features tagged as `categorical` and `continuous` and supports data aggregation methods like `concat` and `elementwise-sum`. It also supports data augmentation techniques like stochastic swap noise. It outputs an interaction representation after combining all features and also the input mask according to the training task (more on this later).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46bc24a",
   "metadata": {},
   "source": [
    "The `max_sequence_length` argument defines the maximum sequence length of our sequential input, and if `continuous_projection` argument is set, all numerical features are concatenated and projected by an MLP block so that continuous features are represented by a vector of size defined by user, which is `64` in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b38d30d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using smaller max_sequence_length for FSI financial data (sequences are typically shorter)\n",
    "inputs = tr.TabularSequenceFeatures.from_schema(\n",
    "        schema,\n",
    "        max_sequence_length=10,  # Reduced for FSI data\n",
    "        continuous_projection=64,\n",
    "        masking=\"mlm\",\n",
    "        d_output=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3feb554",
   "metadata": {},
   "source": [
    "The output of the `TabularSequenceFeatures` module is the sequence of interactions embedding vectors defined in the following steps:\n",
    "- 1. Create sequence inputs: If the schema contains non sequential features, expand each feature to a sequence by repeating the value as many times as the `max_sequence_length` value.  \n",
    "- 2. Get a representation vector of categorical features: Project each sequential categorical feature using the related embedding table. The resulting tensor is of shape (bs, max_sequence_length, embed_dim).\n",
    "- 3. Project scalar values if `continuous_projection` is set : Apply an MLP layer with hidden size equal to `continuous_projection` vector size value. The resulting tensor is of shape (batch_size, max_sequence_length, continuous_projection).\n",
    "- 4. Aggregate the list of features vectors to represent each interaction in the sequence with one vector: For example, `concat` will concat all vectors based on the last dimension `-1` and the resulting tensor will be of shape (batch_size, max_sequence_length, D) where D is the sum over all embedding dimensions and the value of continuous_projection. \n",
    "- 5. If masking schema is set (needed only for the `NextItemPredictionTask` training), the masked labels are derived from the sequence of raw item-ids and the sequence of interactions embeddings are processed to mask information about the masked positions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d656a",
   "metadata": {},
   "source": [
    "### Define the Transformer block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635cd0f3",
   "metadata": {},
   "source": [
    "In the next cell, the whole model is build with a few lines of code. \n",
    "Here is a brief explanation of the main classes:  \n",
    "- [XLNetConfig](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/config/transformer.py#L261) - We have injected in the HF transformers config classes like `XLNetConfig`the `build()` method that provides default configuration to Transformer architectures for session-based recommendation. Here we use it to instantiate and configure an XLNET architecture.  \n",
    "- [TransformerBlock](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/torch/block/transformer.py#L57) class integrates with HF Transformers, which are made available as a sequence processing module for session-based and sequential-based recommendation models.  \n",
    "- [NextItemPredictionTask](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/torch/model/prediction_task.py#L110) supports the next-item prediction task. We also support other predictions [tasks](https://github.com/NVIDIA-Merlin/Transformers4Rec/blob/stable/transformers4rec/torch/model/prediction_task.py), like classification and regression for the whole sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed749ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model recreated with FSI-appropriate metrics (top_ks=[3, 5])\n"
     ]
    }
   ],
   "source": [
    "# Define XLNetConfig class and set default parameters for HF XLNet config  \n",
    "# Updated total_seq_length to match FSI data sequence length\n",
    "transformer_config = tr.XLNetConfig.build(\n",
    "    d_model=64, n_head=4, n_layer=2, total_seq_length=10  # Reduced for FSI data\n",
    ")\n",
    "# Define the model block including: inputs, masking, projection and transformer block.\n",
    "body = tr.SequentialBlock(\n",
    "    inputs, tr.MLPBlock([64]), tr.TransformerBlock(transformer_config, masking=inputs.masking)\n",
    ")\n",
    "\n",
    "# # Define the evaluation top-N metrics and the cut-offs\n",
    "# metrics = [NDCGAt(top_ks=[20, 40], labels_onehot=True),  \n",
    "#            RecallAt(top_ks=[20, 40], labels_onehot=True)]\n",
    "\n",
    "# # Define a head related to next item prediction task \n",
    "# head = tr.Head(\n",
    "#     body,\n",
    "#     tr.NextItemPredictionTask(weight_tying=True, \n",
    "#                               metrics=metrics),\n",
    "#     inputs=inputs,\n",
    "# )\n",
    "\n",
    "# # Get the end-to-end Model class \n",
    "# model = tr.Model(head)\n",
    "\n",
    "\n",
    "# Fix the metrics to match FSI data vocabulary size (8 unique product interactions)\n",
    "# Reduced top_ks from [20, 40] to [3, 5] to avoid \"selected index k out of range\" error\n",
    "metrics = [NDCGAt(top_ks=[3, 5], labels_onehot=True),  \n",
    "           RecallAt(top_ks=[3, 5], labels_onehot=True)]\n",
    "\n",
    "# Redefine the head with the corrected metrics\n",
    "head = tr.Head(\n",
    "    body,\n",
    "    tr.NextItemPredictionTask(weight_tying=True, \n",
    "                              metrics=metrics),\n",
    "    inputs=inputs,\n",
    ")\n",
    "\n",
    "# Get the end-to-end Model class with corrected metrics\n",
    "model = tr.Model(head)\n",
    "\n",
    "print(\"Model recreated with FSI-appropriate metrics (top_ks=[3, 5])\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57335ff",
   "metadata": {},
   "source": [
    "Note that we can easily define an RNN-based model inside the `SequentialBlock` instead of a Transformer-based model. You can explore this [tutorial](https://github.com/NVIDIA-Merlin/Transformers4Rec/tree/stable/examples/tutorial) for a GRU-based model example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d51e39",
   "metadata": {},
   "source": [
    "### Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26d7aec",
   "metadata": {},
   "source": [
    "We use the Merlin Dataloader's PyTorch Dataloader for optimized loading of multiple features from input parquet files. You can learn more about this data loader [here](https://nvidia-merlin.github.io/dataloader)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fd4c22",
   "metadata": {},
   "source": [
    "### **Set Training arguments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ba4286-3808-4688-953e-f93f663219fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_device_train_batch_size = int(os.environ.get(\n",
    "    \"per_device_train_batch_size\", \n",
    "    '128'\n",
    "))\n",
    "\n",
    "per_device_eval_batch_size = int(os.environ.get(\n",
    "    \"per_device_eval_batch_size\", \n",
    "    '32'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693974df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers4rec.config.trainer import T4RecTrainingArguments\n",
    "from transformers4rec.torch import Trainer\n",
    "# Set hyperparameters for training \n",
    "train_args = T4RecTrainingArguments(data_loader_engine='merlin', \n",
    "                                    dataloader_drop_last = True,\n",
    "                                    gradient_accumulation_steps = 1,\n",
    "                                    per_device_train_batch_size = per_device_train_batch_size, \n",
    "                                    per_device_eval_batch_size = per_device_eval_batch_size,\n",
    "                                    output_dir = \"./tmp\", \n",
    "                                    learning_rate=0.0005,\n",
    "                                    lr_scheduler_type='cosine', \n",
    "                                    learning_rate_num_cosine_cycles_by_epoch=1.5,\n",
    "                                    num_train_epochs=5,\n",
    "                                    max_sequence_length=10,  # Updated for FSI data \n",
    "                                    report_to = [],\n",
    "                                    logging_steps=50,\n",
    "                                    no_cuda=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ece64",
   "metadata": {},
   "source": [
    "Note that we add an argument `data_loader_engine='merlin'` to automatically load the features needed for training using the schema. The default value is `merlin` for optimized GPU-based data-loading. Optionally a `PyarrowDataLoader` (pyarrow) can also be used as a basic option, but it is slower and works only for small datasets, as the full data is loaded to CPU memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32554ea0",
   "metadata": {},
   "source": [
    "## Daily Fine-Tuning: Training over a time window"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef883061",
   "metadata": {},
   "source": [
    "Here we do daily fine-tuning meaning that we use the first day to train and second day to evaluate, then we use the second day data to train the model by resuming from the first step, and evaluate on the third day, so on and so forth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f452d09",
   "metadata": {},
   "source": [
    "We have extended the HuggingFace transformers `Trainer` class (PyTorch only) to support evaluation of RecSys metrics. In this example, the evaluation of the session-based recommendation model is performed using traditional Top-N ranking metrics such as Normalized Discounted Cumulative Gain (NDCG@20) and Hit Rate (HR@20). NDCG accounts for rank of the relevant item in the recommendation list and is a more fine-grained metric than HR, which only verifies whether the relevant item is among the top-n items. HR@n is equivalent to Recall@n when there is only one relevant item in the recommendation list.\n",
    "\n",
    "⚠️ **Fix Applied: Metrics Vocabulary Size**\n",
    "\n",
    "**Issue:** The original metrics used `top_ks=[20, 40]` but the FSI dataset only has **8 unique product interactions**. This caused the \\\"selected index k out of range\\\" error during evaluation.\n",
    "\n",
    "**Solution:** Reduced `top_ks` to `[3, 5]` to match the available vocabulary size:\n",
    "\n",
    "- NDCG@3, NDCG@5\n",
    "- Recall@3, Recall@5\n",
    "\n",
    "This ensures the model can properly evaluate top-N recommendations within the constraints of the FSI dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2283f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the T4Rec Trainer, which manages training and evaluation for the PyTorch API\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    schema=schema,\n",
    "    compute_metrics=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d515127c",
   "metadata": {},
   "source": [
    "Define the output folder of the processed parquet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae313150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated for FSI data which spans days 21-30 (based on session_date calculations)\n",
    "start_window_index = int(os.environ.get(\n",
    "    \"start_window_index\", \n",
    "    '21'  # Start from day 21 (first available day in FSI data)\n",
    "))\n",
    "\n",
    "final_window_index = int(os.environ.get(\n",
    "    \"final_window_index\", \n",
    "    '28'  # End at day 28 (to allow evaluation on day 29)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae51de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/data/sessions_by_day/21/train.parquet']\n",
      "********************\n",
      "Launch training for day 21 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11776\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.451200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.172100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.639600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.284100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.200200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.142400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.103900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.077800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.098400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='371' max='46' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [46/46 01:58]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11648\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 22 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.21310661733150482\n",
      " eval_/next-item/ndcg_at_3 = 0.9834765791893005\n",
      " eval_/next-item/ndcg_at_5 = 0.9845873117446899\n",
      " eval_/next-item/recall_at_3 = 0.9972826242446899\n",
      " eval_/next-item/recall_at_5 = 1.0\n",
      " eval_runtime = 1.3336\n",
      " eval_samples_per_second = 1103.81\n",
      " eval_steps_per_second = 34.494\n",
      "['/workspace/data/sessions_by_day/22/train.parquet']\n",
      "********************\n",
      "Launch training for day 22 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='455' max='455' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [455/455 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.076100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.065700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.054200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.059500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.048300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11776\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 23 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.16405370831489563\n",
      " eval_/next-item/ndcg_at_3 = 0.9616813659667969\n",
      " eval_/next-item/ndcg_at_5 = 0.9754325151443481\n",
      " eval_/next-item/recall_at_3 = 0.9680706858634949\n",
      " eval_/next-item/recall_at_5 = 1.0\n",
      " eval_runtime = 1.3185\n",
      " eval_samples_per_second = 1116.413\n",
      " eval_steps_per_second = 34.888\n",
      "['/workspace/data/sessions_by_day/23/train.parquet']\n",
      "********************\n",
      "Launch training for day 23 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.041900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.036800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.037400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.031800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11776\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 24 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.03623492643237114\n",
      " eval_/next-item/ndcg_at_3 = 0.9956164360046387\n",
      " eval_/next-item/ndcg_at_5 = 0.9964941740036011\n",
      " eval_/next-item/recall_at_3 = 0.9979619979858398\n",
      " eval_/next-item/recall_at_5 = 1.0\n",
      " eval_runtime = 1.3274\n",
      " eval_samples_per_second = 1108.912\n",
      " eval_steps_per_second = 34.654\n",
      "['/workspace/data/sessions_by_day/24/train.parquet']\n",
      "********************\n",
      "Launch training for day 24 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.041600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.039200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.035300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.033200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.028400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11904\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 25 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.05560538172721863\n",
      " eval_/next-item/ndcg_at_3 = 0.9964458346366882\n",
      " eval_/next-item/ndcg_at_5 = 0.9964458346366882\n",
      " eval_/next-item/recall_at_3 = 0.9999999403953552\n",
      " eval_/next-item/recall_at_5 = 0.9999999403953552\n",
      " eval_runtime = 1.3546\n",
      " eval_samples_per_second = 1110.26\n",
      " eval_steps_per_second = 34.696\n",
      "['/workspace/data/sessions_by_day/25/train.parquet']\n",
      "********************\n",
      "Launch training for day 25 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='465' max='465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [465/465 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.024500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.030300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.023200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.019100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.021400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11776\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 26 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.06706468760967255\n",
      " eval_/next-item/ndcg_at_3 = 0.98265141248703\n",
      " eval_/next-item/ndcg_at_5 = 0.9831771850585938\n",
      " eval_/next-item/recall_at_3 = 0.998641312122345\n",
      " eval_/next-item/recall_at_5 = 1.0\n",
      " eval_runtime = 1.3288\n",
      " eval_samples_per_second = 1107.764\n",
      " eval_steps_per_second = 34.618\n",
      "['/workspace/data/sessions_by_day/26/train.parquet']\n",
      "********************\n",
      "Launch training for day 26 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.031900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.026500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.029000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.035700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.029600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.020700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.037100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.024300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 11776\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 128\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Eval results for day 27 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.02906179614365101\n",
      " eval_/next-item/ndcg_at_3 = 0.9971369504928589\n",
      " eval_/next-item/ndcg_at_5 = 0.9974295496940613\n",
      " eval_/next-item/recall_at_3 = 0.9993206858634949\n",
      " eval_/next-item/recall_at_5 = 1.0\n",
      " eval_runtime = 1.3377\n",
      " eval_samples_per_second = 1100.404\n",
      " eval_steps_per_second = 34.388\n",
      "['/workspace/data/sessions_by_day/27/train.parquet']\n",
      "********************\n",
      "Launch training for day 27 are:\n",
      "********************\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='460' max='460' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [460/460 00:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.032200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.031500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.022800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.030900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "********************\n",
      "Eval results for day 28 are:\t\n",
      "\n",
      "********************\n",
      "\n",
      " eval_/loss = 0.047439515590667725\n",
      " eval_/next-item/ndcg_at_3 = 0.9977756142616272\n",
      " eval_/next-item/ndcg_at_5 = 0.9977756142616272\n",
      " eval_/next-item/recall_at_3 = 0.9999999403953552\n",
      " eval_/next-item/recall_at_5 = 0.9999999403953552\n",
      " eval_runtime = 1.3639\n",
      " eval_samples_per_second = 1102.72\n",
      " eval_steps_per_second = 34.46\n"
     ]
    }
   ],
   "source": [
    "start_time_window_index = start_window_index\n",
    "final_time_window_index = final_window_index\n",
    "# Iterating over days in the FSI dataset (days 21-28 for training, evaluating on subsequent days)\n",
    "for time_index in range(start_time_window_index, final_time_window_index):\n",
    "    # Set data \n",
    "    time_index_train = time_index\n",
    "    time_index_eval = time_index + 1\n",
    "    train_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_train}/train.parquet\"))\n",
    "    eval_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))\n",
    "    print(train_paths)\n",
    "    \n",
    "    # Train on day related to time_index \n",
    "    print('*'*20)\n",
    "    print(\"Launch training for day %s are:\" %time_index)\n",
    "    print('*'*20 + '\\n')\n",
    "    trainer.train_dataset_or_path = train_paths\n",
    "    trainer.reset_lr_scheduler()\n",
    "    trainer.train()\n",
    "    trainer.state.global_step +=1\n",
    "    print('finished')\n",
    "    \n",
    "    # Evaluate on the following day\n",
    "    trainer.eval_dataset_or_path = eval_paths\n",
    "    train_metrics = trainer.evaluate(metric_key_prefix='eval')\n",
    "    print('*'*20)\n",
    "    print(\"Eval results for day %s are:\\t\" %time_index_eval)\n",
    "    print('\\n' + '*'*20 + '\\n')\n",
    "    for key in sorted(train_metrics.keys()):\n",
    "        print(\" %s = %s\" % (key, str(train_metrics[key]))) \n",
    "    wipe_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d7bd8",
   "metadata": {},
   "source": [
    "### Re-compute evaluation metrics of the validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a34be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_paths = glob.glob(os.path.join(OUTPUT_DIR, f\"{time_index_eval}/valid.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c6867d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  eval_/loss = 0.047439515590667725\n",
      "  eval_/next-item/ndcg_at_3 = 0.9977756142616272\n",
      "  eval_/next-item/ndcg_at_5 = 0.9977756142616272\n",
      "  eval_/next-item/recall_at_3 = 0.9999999403953552\n",
      "  eval_/next-item/recall_at_5 = 0.9999999403953552\n",
      "  eval_runtime = 1.3437\n",
      "  eval_samples_per_second = 1119.259\n",
      "  eval_steps_per_second = 34.977\n"
     ]
    }
   ],
   "source": [
    "# set new data from day 7\n",
    "eval_metrics = trainer.evaluate(eval_dataset=eval_data_paths, metric_key_prefix='eval')\n",
    "for key in sorted(eval_metrics.keys()):\n",
    "    print(\"  %s = %s\" % (key, str(eval_metrics[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b520bd-f6e3-460e-b06d-1bf480cae3cf",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766cd46b-25e7-4d89-9675-152e02103f33",
   "metadata": {},
   "source": [
    "Let's save the model to be able to load it back at inference step. Using `model.save()`, we save the model as a pkl file in the given path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9aebd79-e6e5-4309-a692-917b7b0283d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path= os.environ.get(\"OUTPUT_DIR\", f\"{INPUT_DATA_DIR}/saved_model\")\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26a649",
   "metadata": {},
   "source": [
    "That's it! You have just trained your session-based recommendation model using Transformers4Rec. Now you can move on to the next notebook `03-serving-session-based-model-torch-backend`. Please shut down this kernel to free the GPU memory before you start the next one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af8ecee",
   "metadata": {},
   "source": [
    "Tip: We can easily log and visualize model training and evaluation on [Weights & Biases (W&B)](https://wandb.ai/home), [TensorBoard](https://www.tensorflow.org/tensorboard), or [NVIDIA DLLogger](https://github.com/NVIDIA/dllogger). By default, the HuggingFace transformers `Trainer` (which we extend) uses Weights & Biases (W&B) to log training and evaluation metrics, which provides nice visualization results and comparison between different runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d795d7ca5d3ec3bd6293cc80853205a74ce23d484a2b8f537732a716747107c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
